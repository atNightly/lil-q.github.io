<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/logoforapple.png">
  <link rel="icon" type="image/png" href="/img/logo192.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#13100f">
  <meta name="description" content="Life Goes On">
  <meta name="author" content="戚天天">
  <meta name="keywords" content="python, 机器学习, cpp, 深度学习, 机器视觉, 算法, 数据结构">
  <title>PyTorch基础 - Homeward</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.18.1/styles/tomorrow-night-eighties.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->
<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">



<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->

  <link rel="stylesheet" href="/css/custom.css">


</head>


<body>
  <header style="height: 38vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Homeward</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              Home</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              Archives</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              Categories</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              Tags</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('https://qttblog.oss-cn-hangzhou.aliyuncs.com/after5.5/max-larochelle-7YtI5565PVU-unsplash.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-01-02 17:39">
                    Thursday, January 2nd 2020, 5:39 pm
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    5.7k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    79
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>PyTorch官方中文文档学习笔记</p>
<a id="more"></a>
<h1 id="张量-Tensors"><a href="#张量-Tensors" class="headerlink" title="张量(Tensors)"></a>张量(Tensors)</h1><h2 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h2><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 创建一个5x3的矩阵，不初始化</span>
x_1 = torch.empty(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)

<span class="hljs-comment"># 构造一个随机初始化的矩阵</span>
x_2 = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)

<span class="hljs-comment"># 构造一个矩阵全为 0，而且数据类型是 long</span>
x_3 = torch.zeros(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, dtype=torch.long)

<span class="hljs-comment"># 构造一个张量，直接使用数据</span>
x_4 = torch.tensor([<span class="hljs-number">5.5</span>, <span class="hljs-number">3</span>])</code></pre></div>
<p>输出：</p>
<div class="hljs"><pre><code class="hljs python">x_1: tensor([[<span class="hljs-number">1.2875e-35</span>, <span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">1.2875e-35</span>],
             [<span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">1.7290e-39</span>, <span class="hljs-number">0.0000e+00</span>],
             [<span class="hljs-number">1.7290e-39</span>, <span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">1.2876e-35</span>],
             [<span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">1.2876e-35</span>, <span class="hljs-number">0.0000e+00</span>],
             [<span class="hljs-number">1.2876e-35</span>, <span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">1.2876e-35</span>]])
x_2: tensor([[<span class="hljs-number">0.8532</span>, <span class="hljs-number">0.0308</span>, <span class="hljs-number">0.7529</span>],
             [<span class="hljs-number">0.0109</span>, <span class="hljs-number">0.3987</span>, <span class="hljs-number">0.9199</span>],
             [<span class="hljs-number">0.8618</span>, <span class="hljs-number">0.2898</span>, <span class="hljs-number">0.7708</span>],
             [<span class="hljs-number">0.8400</span>, <span class="hljs-number">0.3074</span>, <span class="hljs-number">0.9531</span>],
             [<span class="hljs-number">0.8799</span>, <span class="hljs-number">0.3668</span>, <span class="hljs-number">0.9811</span>]])
x_3: tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
             [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
             [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
             [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
             [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
x_4: tensor([<span class="hljs-number">5.5000</span>, <span class="hljs-number">3.0000</span>])</code></pre></div>
<h2 id="张量数据类型"><a href="#张量数据类型" class="headerlink" title="张量数据类型"></a>张量数据类型</h2><p>PyTorch提供了9种用于CPU和GPU的张量类型：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Data type</th>
<th>dtype</th>
<th>CPU tensor</th>
<th>GPU tensor</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td><code>torch.float32</code> or <code>torch.float</code></td>
<td><code>torch.FloatTensor</code></td>
<td><code>torch.cuda.FloatTensor</code></td>
</tr>
<tr>
<td>64-bit floating point</td>
<td><code>torch.float64</code> or <code>torch.double</code></td>
<td><code>torch.DoubleTensor</code></td>
<td><code>torch.cuda.DoubleTensor</code></td>
</tr>
<tr>
<td>16-bit floating point</td>
<td><code>torch.float16</code> or <code>torch.half</code></td>
<td><code>torch.HalfTensor</code></td>
<td><code>torch.cuda.HalfTensor</code></td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td><code>torch.uint8</code></td>
<td><code>torch.ByteTensor</code></td>
<td><code>torch.cuda.ByteTensor</code></td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td><code>torch.int8</code></td>
<td><code>torch.CharTensor</code></td>
<td><code>torch.cuda.CharTensor</code></td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td><code>torch.int16</code> or <code>torch.short</code></td>
<td><code>torch.ShortTensor</code></td>
<td><code>torch.cuda.ShortTensor</code></td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td><code>torch.int32</code> or <code>torch.int</code></td>
<td><code>torch.IntTensor</code></td>
<td><code>torch.cuda.IntTensor</code></td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td><code>torch.int64</code> or <code>torch.long</code></td>
<td><code>torch.LongTensor</code></td>
<td><code>torch.cuda.LongTensor</code></td>
</tr>
<tr>
<td>Boolean</td>
<td><code>torch.bool</code></td>
<td><code>torch.BoolTensor</code></td>
<td><code>torch.cuda.BoolTensor</code></td>
</tr>
</tbody>
</table>
</div>
<h2 id="张量的运算"><a href="#张量的运算" class="headerlink" title="张量的运算"></a>张量的运算</h2><h3 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h3><div class="hljs"><pre><code class="hljs python">x_1 = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
print(<span class="hljs-string">'x_1'</span>, x_1, x_1.dtype)

x_2 = x_1 * <span class="hljs-number">2</span>
print(<span class="hljs-string">'x_2'</span>, x_2)

<span class="hljs-comment"># 加法一</span>
y_1 = x_1 + x_2
print(<span class="hljs-string">'y_1'</span>, y_1)

<span class="hljs-comment"># 加法二</span>
y_2 = torch.add(x_1, x_2)
print(<span class="hljs-string">'y_2'</span>, y_2)

<span class="hljs-comment"># 加法三</span>
y_3 = x_1.add(x_2)
print(<span class="hljs-string">'y_3'</span>, y_3)
print(<span class="hljs-string">'x_1'</span>, x_1)

<span class="hljs-comment"># 加法四(in-place)</span>
y_3 = x_1.add_(x_2)
print(<span class="hljs-string">'y_3'</span>, y_3)
print(<span class="hljs-string">'x_1'</span>, x_1)</code></pre></div>
<p>输出：</p>
<div class="hljs"><pre><code class="hljs python">x_1 tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],
            [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],
            [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]) torch.float32
x_2 tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>],
            [<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>],
            [<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]])
<span class="hljs-comment"># 加法一：</span>
y_1 tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
        	[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
        	[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])
<span class="hljs-comment"># 加法二：</span>
y_2 tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
        	[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
        	[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])
<span class="hljs-comment"># 加法三：</span>
y_3 tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])
x_1 tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],
            [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],
            [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])
<span class="hljs-comment"># 加法四(in-place)：</span>
y_3 tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])
x_1 tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>],
            [<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])</code></pre></div>
<h3 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h3><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 哈达玛积(element wise，对应元素相乘)</span>
<span class="hljs-comment"># mul和*等效</span>
y_4 = torch.mul(x_1, x_2)
y_5 = x_1*x_2

<span class="hljs-comment"># 矩阵相乘</span>
<span class="hljs-comment"># matmul和mm等效</span>
y_6 = torch.matmul(x_1, x_2)
y_7 = torch.mm(x_1, x_2)
y_8 = x_1.mm(x_2)</code></pre></div>
<p>输出：</p>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 哈达玛积(element wise，对应元素相乘)</span>
<span class="hljs-comment"># mul和*等效</span>
<span class="hljs-comment"># 注意：x_1中的值已经变成3了</span>
y_4 tensor([[<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],
            [<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],
            [<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>]])
y_5 tensor([[<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],
            [<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],
            [<span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>]])
<span class="hljs-comment"># 矩阵相乘</span>
<span class="hljs-comment"># matmul和mm等效</span>
y_6 tensor([[<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>]])
y_7 tensor([[<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>]])
y_8 tensor([[<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>],
            [<span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>, <span class="hljs-number">18.</span>]])</code></pre></div>
<h2 id="自动微分"><a href="#自动微分" class="headerlink" title="自动微分"></a>自动微分</h2><p><code>torch.Tensor</code> 是包的核心类。如果将其属性 <code>.requires_grad</code>设置为<code>True</code>，则会开始跟踪针对 <code>tensor</code> 的所有操作。完成计算后，您可以调用 <code>.backward()</code>来自动计算所有梯度。该张量的梯度将累积到<code>.grad</code>属性中。</p>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch
x = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
print(x.requires_grad)

<span class="hljs-comment"># print: False</span>

x.requires_grad_(<span class="hljs-literal">True</span>)

<span class="hljs-comment"># print: tensor([[1., 1.],</span>
<span class="hljs-comment">#        	     [1., 1.]], requires_grad=True)</span></code></pre></div>
<p>还有一个类对于 <code>autograd</code> 实现非常重要那就是 <code>Function</code>。<code>Tensor</code> 和 <code>Function</code> 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。每个张量都有一个 <code>.grad_fn</code> 属性保存着创建了张量的 <code>Function</code> 的引用，（如果用户自己创建张量，则<code>grad_fn</code> 是 <code>None</code> ）。</p>
<p>如果你想计算导数，你可以调用 <code>Tensor.backward()</code>。如果 <code>Tensor</code> 是标量（<strong>即它包含一个元素数据，相当于权重是1</strong>），则不需要指定任何参数<code>backward()</code>，但是如果它有更多元素，则需要指定一个<code>gradient</code> 参数（<strong>每个维度的权重</strong>）来指定张量的形状。</p>
<div class="hljs"><pre><code class="hljs python">y = x + <span class="hljs-number">2</span>
print(y)

<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># tensor([[3., 3.],</span>
<span class="hljs-comment">#         [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</span>

print(y.grad_fn)

<span class="hljs-comment"># print: (y 作为操作的结果被创建，所以它有 grad_fn)</span>
<span class="hljs-comment"># &lt;AddBackward0 object at 0x7fe1db427470&gt;</span>

z = y * y * <span class="hljs-number">3</span>
out = z.mean()
print(z, out)

<span class="hljs-comment"># print: </span>
<span class="hljs-comment"># tensor([[27., 27.],</span>
<span class="hljs-comment">#         [27., 27.]], grad_fn=&lt;MulBackward0&gt;) </span>
<span class="hljs-comment"># tensor(27., grad_fn=&lt;MeanBackward0&gt;)</span>

out.backward()
print(x.grad)

<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># tensor([[4.5000, 4.5000],</span>
<span class="hljs-comment">#        [4.5000, 4.5000]])</span></code></pre></div>
<p>需要输入权重的雅克比向量积的例子：</p>
<div class="hljs"><pre><code class="hljs python">x = torch.randn(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)
y = x * <span class="hljs-number">2</span>
<span class="hljs-keyword">while</span> y.data.norm() &lt; <span class="hljs-number">1000</span>:
    y = y * <span class="hljs-number">2</span>
print(y)

<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># tensor([ -444.6791,   762.9810, -1690.0941], grad_fn=&lt;MulBackward0&gt;)</span>

v = torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0001</span>], dtype=torch.float)
y.backward(v)
print(x.grad)

<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])</span></code></pre></div>
<p>要停止<code>tensor</code>历史记录的跟踪，可以调用<code>.detach()</code>，它将其与计算历史记录分离，并防止将来的计算被跟踪。还可以将代码块使用 <code>with torch.no_grad():</code> 包装起来。在评估模型时，这是特别有用，因为模型在训练阶段具有 <code>requires_grad = True</code>的可训练参数有利于调参，但在评估阶段我们不需要梯度。</p>
<div class="hljs"><pre><code class="hljs python">print(x.requires_grad)
print((x ** <span class="hljs-number">2</span>).requires_grad)

<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># True</span>
<span class="hljs-comment"># True</span>

<span class="hljs-keyword">with</span> torch.no_grad():
    print((x ** <span class="hljs-number">2</span>).requires_grad)
    
<span class="hljs-comment"># print:</span>
<span class="hljs-comment"># False</span></code></pre></div>
<h1 id="数据-Dataset"><a href="#数据-Dataset" class="headerlink" title="数据(Dataset)"></a>数据(Dataset)</h1><p>本节内容针对<a href="http://pytorch123.com/ThirdSection/DataLoding/" target="_blank" rel="noopener">PyTorch中文文档-数据加载和处理</a>。</p>
<h2 id="建立数据集"><a href="#建立数据集" class="headerlink" title="建立数据集"></a>建立数据集</h2><p><code>torch.utils.data.Dataset</code>是代表自定义数据集方法的<a href="https://www.runoob.com/java/java-abstraction.html" target="_blank" rel="noopener">抽象类</a>，你可以自己定义你的数据类继承这个抽象类，非常简单，只需要定义<code>__len__</code>和<code>__getitem__</code>这两个方法就可以。</p>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FaceLandmarksDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-string">"""面部标记数据集."""</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, csv_file, root_dir, transform=None)</span>:</span>
        <span class="hljs-string">"""
        csv_file（string）：带注释的csv文件的路径。
        root_dir（string）：包含所有图像的目录。
        transform（callable， optional）：一个样本上的可用的可选变换
        """</span>
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.landmarks_frame)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, idx)</span>:</span>
        <span class="hljs-comment"># 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略。</span>
        <span class="hljs-comment"># iloc相当于切片。index location</span>
        img_name = os.path.join(self.root_dir,
                                self.landmarks_frame.iloc[idx, <span class="hljs-number">0</span>])
        <span class="hljs-comment"># skimage.io.imread: 直接返回numpy.ndarray 对象，通道顺序为RGB，通道值默认范围0-255，uint8。</span>
        image = io.imread(img_name)
        landmarks = self.landmarks_frame.iloc[idx, <span class="hljs-number">1</span>:]
        landmarks = np.array([landmarks])
        <span class="hljs-comment"># uint8-&gt;float</span>
        landmarks = landmarks.astype(<span class="hljs-string">'float'</span>).reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>)
        sample = &#123;<span class="hljs-string">'image'</span>: image, <span class="hljs-string">'landmarks'</span>: landmarks&#125;

        <span class="hljs-keyword">if</span> self.transform:
            sample = self.transform(sample)

        <span class="hljs-keyword">return</span> sample</code></pre></div>
<h2 id="数据变形"><a href="#数据变形" class="headerlink" title="数据变形"></a>数据变形</h2><p>通过上面的例子我们会发现图片并不是同样的尺寸。绝大多数神经网络都假定图片的尺寸相同。因此我们需要做一些预处理。让我们创建三个转换: <em> <code>Rescale</code>：缩放图片 </em> <code>RandomCrop</code>：对图片进行随机裁剪。这是一种数据增强操作 * <code>ToTensor</code>：把numpy格式图片转为torch格式图片 (我们需要交换坐标轴).</p>
<p>我们会把它们写成可调用的类的形式而不是简单的函数，这样就不需要每次调用时传递一遍参数。我们只需要实现<code>__call__</code>方法，必 要的时候实现 <code>__init__</code>方法。我们可以这样调用这些转换:</p>
<div class="hljs"><pre><code class="hljs python">tsfm = Transform(params)
transformed_sample = tsfm(sample)</code></pre></div>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Rescale</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">"""将样本中的图像重新缩放到给定大小。.

    Args:
        output_size（tuple或int）：所需的输出大小。 如果是元组，则输出为
         与output_size匹配。 如果是int，则匹配较小的图像边缘到output_size保持纵横比相同。
    """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, output_size)</span>:</span>
        <span class="hljs-keyword">assert</span> isinstance(output_size, (int, tuple))
        self.output_size = output_size

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(self, sample)</span>:</span>
        image, landmarks = sample[<span class="hljs-string">'image'</span>], sample[<span class="hljs-string">'landmarks'</span>]

        h, w = image.shape[:<span class="hljs-number">2</span>]
        <span class="hljs-keyword">if</span> isinstance(self.output_size, int):
            <span class="hljs-keyword">if</span> h &gt; w:
                new_h, new_w = self.output_size * h / w, self.output_size
            <span class="hljs-keyword">else</span>:
                new_h, new_w = self.output_size, self.output_size * w / h
        <span class="hljs-keyword">else</span>:
            new_h, new_w = self.output_size

        new_h, new_w = int(new_h), int(new_w)

        img = transform.resize(image, (new_h, new_w))

        <span class="hljs-comment"># h and w are swapped for landmarks because for images,</span>
        <span class="hljs-comment"># x and y axes are axis 1 and 0 respectively</span>
        landmarks = landmarks * [new_w / w, new_h / h]

        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">'image'</span>: img, <span class="hljs-string">'landmarks'</span>: landmarks&#125;


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomCrop</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">"""随机裁剪样本中的图像.

    Args:
       output_size（tuple或int）：所需的输出大小。 如果是int，方形裁剪是。         
    """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, output_size)</span>:</span>
        <span class="hljs-keyword">assert</span> isinstance(output_size, (int, tuple))
        <span class="hljs-keyword">if</span> isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">assert</span> len(output_size) == <span class="hljs-number">2</span>
            self.output_size = output_size

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(self, sample)</span>:</span>
        image, landmarks = sample[<span class="hljs-string">'image'</span>], sample[<span class="hljs-string">'landmarks'</span>]

        h, w = image.shape[:<span class="hljs-number">2</span>]
        new_h, new_w = self.output_size

        top = np.random.randint(<span class="hljs-number">0</span>, h - new_h)
        left = np.random.randint(<span class="hljs-number">0</span>, w - new_w)

        image = image[top: top + new_h,
                      left: left + new_w]

        landmarks = landmarks - [left, top]

        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">'image'</span>: image, <span class="hljs-string">'landmarks'</span>: landmarks&#125;


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ToTensor</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">"""将样本中的ndarrays转换为Tensors."""</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(self, sample)</span>:</span>
        image, landmarks = sample[<span class="hljs-string">'image'</span>], sample[<span class="hljs-string">'landmarks'</span>]

        <span class="hljs-comment"># 交换颜色轴因为</span>
        <span class="hljs-comment"># numpy包的图片是: H * W * C</span>
        <span class="hljs-comment"># torch包的图片是: C * H * W</span>
        image = image.transpose((<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">'image'</span>: torch.from_numpy(image),
                <span class="hljs-string">'landmarks'</span>: torch.from_numpy(landmarks)&#125;</code></pre></div>
<p>可以调用一个简单的类 <code>torchvision.transforms.Compose</code>来实现组合变换。</p>
<div class="hljs"><pre><code class="hljs python">scale = Rescale(<span class="hljs-number">256</span>)
crop = RandomCrop(<span class="hljs-number">128</span>)
composed = transforms.Compose([Rescale(<span class="hljs-number">256</span>),
                               RandomCrop(<span class="hljs-number">224</span>)])</code></pre></div>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p><code>torch.utils.data.DataLoader</code>是一个提供上述所有这些功能的迭代器。下面使用的参数必须是清楚的。一个值得关注的参数是<code>collate_fn</code>, 可以通过它来决定如何对数据进行批处理。但是绝大多数情况下默认值就能运行良好。</p>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># Windows下num_workers值取0不会报错，取其他值可能出现多线程bug</span>
dataloader = DataLoader(transformed_dataset, batch_size=<span class="hljs-number">4</span>,
                        shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">4</span>)</code></pre></div>
<h1 id="TensorFlow-和-PyTorch"><a href="#TensorFlow-和-PyTorch" class="headerlink" title="TensorFlow 和 PyTorch"></a>TensorFlow 和 PyTorch</h1><p>PyTorch自动求导看起来非常像TensorFlow：这两个框架中，我们都定义计算图，使用自动微分来计算梯度。两者最大的不同就是TensorFlow的计算图是静态的，而PyTorch使用动态的计算图。</p>
<p>在TensorFlow中，我们定义计算图一次，然后重复执行这个相同的图，可能会提供不同的输入数据。而在PyTorch中，每一个前向通道定义一个新的计算图。</p>
<p>静态图的好处在于你可以预先对图进行优化。例如，一个框架可能要融合一些图的运算来提升效率，或者产生一个策略来将图分布到多个GPU或机器上。如果重复使用相同的图，那么在重复运行同一个图时，，前期潜在的代价高昂的预先优化的消耗就会被分摊开。</p>
<p>在TensorFlow中，更新权重值的行为是计算图的一部分; 但在PyTorch中，这发生在计算图形之外。</p>
<h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p>实际中，基本没有人会从零开始（随机初始化）训练一个完整的卷积网络，因为相对于网络，很难得到一个足够大的数据集[网络很深, 需要足够大数据集]。通常的做法是在一个很大的数据集上进行预训练得到卷积网络ConvNet, 然后将这个ConvNet的参数作为目标任务的初始化参数或者固定这些参数。</p>
<p>转移学习的两个主要场景：</p>
<ul>
<li>微调<strong>Convnet</strong>：使用预训练的网络(如在<code>imagenet 1000</code>上训练而来的网络)来初始化自己的网络，而不是随机初始化。其他的训练步骤不变。</li>
<li>将<strong>Convnet</strong>看成固定的特征提取器:首先固定ConvNet除了最后的全连接层外的其他所有层。最后的全连接层被替换成一个新的随机 初始化的层，只有这个新的层会被训练[只有这层参数会在反向传播时更新]。</li>
</ul>
<h2 id="微调Torchvision"><a href="#微调Torchvision" class="headerlink" title="微调Torchvision"></a>微调Torchvision</h2><p><a href="http://pytorch123.com/FourSection/FinetuningTorchVisionModel/" target="_blank" rel="noopener">原文</a>，整理成<code>.py</code>后运行会报错，需要把主程序放入<code>if __name__ == &#39;__main__&#39;:</code>下，或者将<code>num_workers</code>置为0。似乎是一个多进程处理的bug，即使修改，在PyCharm下运行完会进入死循环。</p>
<div class="hljs"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span>
<span class="hljs-comment"># coding: utf-8</span>

<span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function
<span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> division
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torchvision
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, models, transforms
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> copy

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_model</span><span class="hljs-params">(model, dataloaders, criterion, optimizer, num_epochs=<span class="hljs-number">25</span>, is_inception=False)</span>:</span> 
    since = time.time()
    val_acc_history = []

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = <span class="hljs-number">0.0</span>

    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
        print(<span class="hljs-string">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class="hljs-number">1</span>))
        print(<span class="hljs-string">'-'</span> * <span class="hljs-number">10</span>)

        <span class="hljs-comment"># 每个epoch都有一个训练和验证阶段</span>
        <span class="hljs-keyword">for</span> phase <span class="hljs-keyword">in</span> [<span class="hljs-string">'train'</span>, <span class="hljs-string">'val'</span>]:
            <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:
                model.train()  <span class="hljs-comment"># Set model to training mode</span>
            <span class="hljs-keyword">else</span>:
                model.eval()   <span class="hljs-comment"># Set model to evaluate mode</span>

            running_loss = <span class="hljs-number">0.0</span>
            running_corrects = <span class="hljs-number">0</span>

            <span class="hljs-comment"># 迭代数据</span>
            <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                <span class="hljs-comment"># 零参数梯度</span>
                optimizer.zero_grad()

                <span class="hljs-comment"># 前向</span>
                <span class="hljs-comment"># 如果只在训练时则跟踪轨迹</span>
                <span class="hljs-keyword">with</span> torch.set_grad_enabled(phase == <span class="hljs-string">'train'</span>):
                    <span class="hljs-comment"># 获取模型输出并计算损失</span>
                    <span class="hljs-comment"># 开始的特殊情况，因为在训练中它有一个辅助输出。</span>
                    <span class="hljs-comment"># 在训练模式下，我们通过将最终输出和辅助输出相加来计算损耗</span>
                    <span class="hljs-comment"># 但在测试中我们只考虑最终输出。</span>
                    <span class="hljs-keyword">if</span> is_inception <span class="hljs-keyword">and</span> phase == <span class="hljs-string">'train'</span>:
                        <span class="hljs-comment"># From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958</span>
                        outputs, aux_outputs = model(inputs)
                        loss1 = criterion(outputs, labels)
                        loss2 = criterion(aux_outputs, labels)
                        loss = loss1 + <span class="hljs-number">0.4</span>*loss2
                    <span class="hljs-keyword">else</span>:
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)

                    _, preds = torch.max(outputs, <span class="hljs-number">1</span>)

                    <span class="hljs-comment"># backward + optimize only if in training phase</span>
                    <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:
                        loss.backward()
                        optimizer.step()

                <span class="hljs-comment"># 统计</span>
                running_loss += loss.item() * inputs.size(<span class="hljs-number">0</span>)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

            print(<span class="hljs-string">'&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'</span>.format(phase, epoch_loss, epoch_acc))

            <span class="hljs-comment"># deep copy the model</span>
            <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'val'</span> <span class="hljs-keyword">and</span> epoch_acc &gt; best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'val'</span>:
                val_acc_history.append(epoch_acc)

        print()

    time_elapsed = time.time() - since
    print(<span class="hljs-string">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(time_elapsed // <span class="hljs-number">60</span>, time_elapsed % <span class="hljs-number">60</span>))
    print(<span class="hljs-string">'Best val Acc: &#123;:4f&#125;'</span>.format(best_acc))

    <span class="hljs-comment"># load best model weights</span>
    model.load_state_dict(best_model_wts)
    <span class="hljs-keyword">return</span> model, val_acc_history

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">set_parameter_requires_grad</span><span class="hljs-params">(model, feature_extracting)</span>:</span>
    <span class="hljs-keyword">if</span> feature_extracting:
        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters():
            param.requires_grad = <span class="hljs-literal">False</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initialize_model</span><span class="hljs-params">(model_name, num_classes, feature_extract, use_pretrained=True)</span>:</span>
    <span class="hljs-comment"># 初始化将在此if语句中设置的这些变量。 </span>
    <span class="hljs-comment"># 每个变量都是模型特定的。</span>
    model_ft = <span class="hljs-literal">None</span>
    input_size = <span class="hljs-number">0</span>

    <span class="hljs-keyword">if</span> model_name == <span class="hljs-string">"resnet"</span>:
        <span class="hljs-string">""" Resnet18
 """</span>
        model_ft = models.resnet18(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = <span class="hljs-number">224</span>

    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">"alexnet"</span>:
        <span class="hljs-string">""" Alexnet
 """</span>
        model_ft = models.alexnet(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[<span class="hljs-number">6</span>].in_features
        model_ft.classifier[<span class="hljs-number">6</span>] = nn.Linear(num_ftrs,num_classes)
        input_size = <span class="hljs-number">224</span>

    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">"vgg"</span>:
        <span class="hljs-string">""" VGG11_bn
 """</span>
        model_ft = models.vgg11_bn(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[<span class="hljs-number">6</span>].in_features
        model_ft.classifier[<span class="hljs-number">6</span>] = nn.Linear(num_ftrs,num_classes)
        input_size = <span class="hljs-number">224</span>

    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">"squeezenet"</span>:
        <span class="hljs-string">""" Squeezenet
 """</span>
        model_ft = models.squeezenet1_0(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        model_ft.classifier[<span class="hljs-number">1</span>] = nn.Conv2d(<span class="hljs-number">512</span>, num_classes, kernel_size=(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))
        model_ft.num_classes = num_classes
        input_size = <span class="hljs-number">224</span>

    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">"densenet"</span>:
        <span class="hljs-string">""" Densenet
 """</span>
        model_ft = models.densenet121(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier.in_features
        model_ft.classifier = nn.Linear(num_ftrs, num_classes)
        input_size = <span class="hljs-number">224</span>

    <span class="hljs-keyword">elif</span> model_name == <span class="hljs-string">"inception"</span>:
        <span class="hljs-string">""" Inception v3
 Be careful, expects (299,299) sized images and has auxiliary output
 """</span>
        model_ft = models.inception_v3(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        <span class="hljs-comment"># 处理辅助网络</span>
        num_ftrs = model_ft.AuxLogits.fc.in_features
        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)
        <span class="hljs-comment"># 处理主要网络</span>
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs,num_classes)
        input_size = <span class="hljs-number">299</span>

    <span class="hljs-keyword">else</span>:
        print(<span class="hljs-string">"Invalid model name, exiting..."</span>)
        exit()

    <span class="hljs-keyword">return</span> model_ft, input_size

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:

    <span class="hljs-comment"># 顶级数据目录。 这里我们假设目录的格式符合ImageFolder结构</span>
    data_dir = <span class="hljs-string">"./hymenoptera_data"</span>

    <span class="hljs-comment"># 从[resnet, alexnet, vgg, squeezenet, densenet, inception]中选择模型</span>
    model_name = <span class="hljs-string">"squeezenet"</span>

    <span class="hljs-comment"># 数据集中类别数量</span>
    num_classes = <span class="hljs-number">2</span>

    <span class="hljs-comment"># 训练的批量大小（根据您的内存量而变化）</span>
    batch_size = <span class="hljs-number">8</span>

    <span class="hljs-comment"># 你要训练的epoch数</span>
    num_epochs = <span class="hljs-number">15</span>

    <span class="hljs-comment"># 用于特征提取的标志。 当为False时，我们微调整个模型，</span>
    <span class="hljs-comment"># 当True时我们只更新重新形成的图层参数</span>
    feature_extract = <span class="hljs-literal">True</span>

    <span class="hljs-comment"># 在这步中初始化模型</span>
    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># 打印我们刚刚实例化的模型</span>
    print(<span class="hljs-string">'model_ft'</span>)

    <span class="hljs-comment"># 数据扩充和训练规范化</span>
    <span class="hljs-comment"># 只需验证标准化</span>
    data_transforms = &#123;
        <span class="hljs-string">'train'</span>: transforms.Compose([
            transforms.RandomResizedCrop(input_size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])
        ]),
        <span class="hljs-string">'val'</span>: transforms.Compose([
            transforms.Resize(input_size),
            transforms.CenterCrop(input_size),
            transforms.ToTensor(),
            transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])
        ]),
    &#125;

    print(<span class="hljs-string">"Initializing Datasets and Dataloaders..."</span>)

    <span class="hljs-comment"># 创建训练和验证数据集</span>
    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-string">'train'</span>, <span class="hljs-string">'val'</span>]&#125;
    <span class="hljs-comment"># 创建训练和验证数据加载器</span>
    dataloaders_dict = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-string">'train'</span>, <span class="hljs-string">'val'</span>]&#125;

    <span class="hljs-comment"># 检测我们是否有可用的GPU</span>
    device = torch.device(<span class="hljs-string">"cuda:0"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)

    <span class="hljs-comment"># 将模型发送到GPU</span>
    model_ft = model_ft.to(device)

    <span class="hljs-comment"># 在此运行中收集要优化/更新的参数。</span>
    <span class="hljs-comment"># 如果我们正在进行微调，我们将更新所有参数。</span>
    <span class="hljs-comment"># 但如果我们正在进行特征提取方法，我们只会更新刚刚初始化的参数，即`requires_grad`的参数为True。</span>
    params_to_update = model_ft.parameters()
    print(<span class="hljs-string">"Params to learn:"</span>)
    <span class="hljs-keyword">if</span> feature_extract:
        params_to_update = []
        <span class="hljs-keyword">for</span> name,param <span class="hljs-keyword">in</span> model_ft.named_parameters():
            <span class="hljs-keyword">if</span> param.requires_grad == <span class="hljs-literal">True</span>:
                params_to_update.append(param)
                print(<span class="hljs-string">"\t"</span>,name)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">for</span> name,param <span class="hljs-keyword">in</span> model_ft.named_parameters():
            <span class="hljs-keyword">if</span> param.requires_grad == <span class="hljs-literal">True</span>:
                print(<span class="hljs-string">"\t"</span>,name)

    <span class="hljs-comment"># 观察所有参数都在优化</span>
    optimizer_ft = optim.SGD(params_to_update, lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)

    <span class="hljs-comment"># 设置损失函数</span>
    criterion = nn.CrossEntropyLoss()

    <span class="hljs-comment"># Train and evaluate</span>
    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==<span class="hljs-string">"inception"</span>))</code></pre></div>
<h1 id="保存与加载模型"><a href="#保存与加载模型" class="headerlink" title="保存与加载模型"></a>保存与加载模型</h1><p>当保存和加载模型时，需要熟悉三个核心功能：</p>
<ol>
<li><code>torch.save</code>：将序列化对象保存到磁盘。此函数使用Python的<code>pickle</code>模块进行序列化。使用此函数可以保存如模型、tensor、字典等各种对象。</li>
<li><code>torch.load</code>：使用pickle的<code>unpickling</code>功能将pickle对象文件反序列化到内存。此功能还可以有助于设备加载数据。</li>
<li><code>torch.nn.Module.load_state_dict</code>：使用反序列化函数 state_dict 来加载模型的参数字典。</li>
</ol>
<h2 id="状态字典-state-dict"><a href="#状态字典-state-dict" class="headerlink" title="状态字典(state_dict)"></a>状态字典(state_dict)</h2><p>在PyTorch中，<code>torch.nn.Module</code>模型的可学习参数（即权重和偏差）包含在模型的参数中，（使用<code>model.parameters()</code>可以进行访问）。 <code>state_dict</code>是Python字典对象，它将每一层映射到其参数张量。注意，只有具有可学习参数的层（如卷积层，线性层等）的模型 才具有<code>state_dict</code>这一项。目标优化<code>torch.optim</code>也有<code>state_dict</code>属性，它包含有关优化器的状态信息，以及使用的超参数。</p>
<p>因为state_dict的对象是Python字典，所以它们可以很容易的保存、更新、修改和恢复，为PyTorch模型和优化器添加了大量模块。</p>
<h2 id="保存和加载推理模型"><a href="#保存和加载推理模型" class="headerlink" title="保存和加载推理模型"></a>保存和加载推理模型</h2><ul>
<li>保存</li>
</ul>
<div class="hljs"><pre><code class="hljs python">torch.save(model.state_dict(), PATH)</code></pre></div>
<ul>
<li>加载</li>
</ul>
<div class="hljs"><pre><code class="hljs python">model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH))
model.eval()</code></pre></div>
<p>当保存好模型用来推断的时候，只需要保存模型学习到的参数，使用<code>torch.save()</code>函数来保存模型<code>state_dict</code>，在 PyTorch 中最常见的模型保存使‘.pt’或者是‘.pth’作为模型文件扩展名。</p>
<p>请记住在运行<code>evaluation</code>之前，务必调用<code>model.eval()</code>去设置 dropout 和 batch normalization 为评估。如果不这样做，有可能得到不一致的<code>evaluation</code>结果。 如果你想要恢复训练，请调用<code>model.train()</code>以确保这些层处于训练模式。</p>
<ul>
<li>注意</li>
</ul>
<p><code>load_state_dict()</code>函数只接受字典对象，而不是保存对象的路径。这就意味着在你传给<code>load_state_dict()</code>函数之前，你必须反序列化 你保存的<code>state_dict</code>。例如，你无法通过 <code>model.load_state_dict(PATH)</code>来加载模型。</p>
<h2 id="保存和加载-Checkpoint-用于推理-继续训练"><a href="#保存和加载-Checkpoint-用于推理-继续训练" class="headerlink" title="保存和加载 Checkpoint 用于推理/继续训练"></a>保存和加载 Checkpoint 用于推理/继续训练</h2><ul>
<li>保存</li>
</ul>
<div class="hljs"><pre><code class="hljs python">torch.save(&#123;
            <span class="hljs-string">'epoch'</span>: epoch,
            <span class="hljs-string">'model_state_dict'</span>: model.state_dict(),
            <span class="hljs-string">'optimizer_state_dict'</span>: optimizer.state_dict(),
            <span class="hljs-string">'loss'</span>: loss,
            ...
            &#125;, PATH)</code></pre></div>
<ul>
<li>加载</li>
</ul>
<div class="hljs"><pre><code class="hljs python">model = TheModelClass(*args, **kwargs)
optimizer = TheOptimizerClass(*args, **kwargs)

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint[<span class="hljs-string">'model_state_dict'</span>])
optimizer.load_state_dict(checkpoint[<span class="hljs-string">'optimizer_state_dict'</span>])
epoch = checkpoint[<span class="hljs-string">'epoch'</span>]
loss = checkpoint[<span class="hljs-string">'loss'</span>]

model.eval()
<span class="hljs-comment"># - or -</span>
model.train()</code></pre></div>
<p>当保存成 Checkpoint 的时候，可用于推理或者是继续训练，保存的不仅仅是模型的 state_dict 。保存优化器的 state_dict 也很重要, 因为它包含作为模型训练更新的缓冲区和参数。你也许想保存其他项目，比如最新记录的训练损失，外部的<code>torch.nn.Embedding</code>层等等。</p>
<p>要保存多个组件，请在字典中组织它们并使用<code>torch.save()</code>来序列化字典。PyTorch 中常见的保存checkpoint 是使用 .tar 文件扩展名。</p>
<p>要加载项目，首先需要初始化模型和优化器，然后使用<code>torch.load()</code>来加载本地字典。这里,你可以非常容易的通过简单查询字典来访问你所保存的项目。</p>
<h2 id="在一个文件中保存多个模型"><a href="#在一个文件中保存多个模型" class="headerlink" title="在一个文件中保存多个模型"></a>在一个文件中保存多个模型</h2><ul>
<li>保存</li>
</ul>
<div class="hljs"><pre><code class="hljs python">torch.save(&#123;
            <span class="hljs-string">'modelA_state_dict'</span>: modelA.state_dict(),
            <span class="hljs-string">'modelB_state_dict'</span>: modelB.state_dict(),
            <span class="hljs-string">'optimizerA_state_dict'</span>: optimizerA.state_dict(),
            <span class="hljs-string">'optimizerB_state_dict'</span>: optimizerB.state_dict(),
            ...
            &#125;, PATH)</code></pre></div>
<ul>
<li>加载</li>
</ul>
<div class="hljs"><pre><code class="hljs python">modelA = TheModelAClass(*args, **kwargs)
modelB = TheModelBClass(*args, **kwargs)
optimizerA = TheOptimizerAClass(*args, **kwargs)
optimizerB = TheOptimizerBClass(*args, **kwargs)

checkpoint = torch.load(PATH)
modelA.load_state_dict(checkpoint[<span class="hljs-string">'modelA_state_dict'</span>])
modelB.load_state_dict(checkpoint[<span class="hljs-string">'modelB_state_dict'</span>])
optimizerA.load_state_dict(checkpoint[<span class="hljs-string">'optimizerA_state_dict'</span>])
optimizerB.load_state_dict(checkpoint[<span class="hljs-string">'optimizerB_state_dict'</span>])

modelA.eval()
modelB.eval()
<span class="hljs-comment"># - or -</span>
modelA.train()
modelB.train()</code></pre></div>
<p>当保存一个模型由多个<code>torch.nn.Modules</code>组成时，例如GAN(对抗生成网络)、sequence-to-sequence (序列到序列模型), 或者是多个模 型融合, 可以采用与保存常规检查点相同的方法。换句话说，保存每个模型的 state_dict 的字典和相对应的优化器。如前所述，可以通 过简单地将它们附加到字典的方式来保存任何其他项目，这样有助于恢复训练。</p>
<p>PyTorch 中常见的保存 checkpoint 是使用 .tar 文件扩展名。</p>
<p>要加载项目，首先需要初始化模型和优化器，然后使用<code>torch.load()</code>来加载本地字典。这里，你可以非常容易的通过简单查询字典来访问你所保存的项目。</p>
<h2 id="使用在不同模型参数下的热启动模式"><a href="#使用在不同模型参数下的热启动模式" class="headerlink" title="使用在不同模型参数下的热启动模式"></a>使用在不同模型参数下的热启动模式</h2><ul>
<li>保存</li>
</ul>
<div class="hljs"><pre><code class="hljs python">torch.save(modelA.state_dict(), PATH)</code></pre></div>
<ul>
<li>加载</li>
</ul>
<div class="hljs"><pre><code class="hljs python">modelB = TheModelBClass(*args, **kwargs)
modelB.load_state_dict(torch.load(PATH), strict=<span class="hljs-literal">False</span>)</code></pre></div>
<p>在迁移学习或训练新的复杂模型时，部分加载模型或加载部分模型是常见的情况。利用训练好的参数，有助于热启动训练过程，并希望帮助你的模型比从头开始训练能够更快地收敛。</p>
<p>无论是从缺少某些键的 state_dict 加载还是从键的数目多于加载模型的 state_dict , 都可以通过在<code>load_state_dict()</code>函数中将<code>strict</code>参数设置为 False 来忽略非匹配键的函数。</p>
<p>如果要将参数从一个层加载到另一个层，但是某些键不匹配，主要修改正在加载的 state_dict 中的参数键的名称以匹配要在加载到模型中的键即可。</p>
<h2 id="通过设备保存-加载模型"><a href="#通过设备保存-加载模型" class="headerlink" title="通过设备保存/加载模型"></a>通过设备保存/加载模型</h2><h3 id="Save-on-GPU-Load-on-CPU"><a href="#Save-on-GPU-Load-on-CPU" class="headerlink" title="Save on GPU, Load on CPU"></a>Save on GPU, Load on CPU</h3><p><strong>Save:</strong></p>
<div class="hljs"><pre><code class="hljs plain">torch.save(model.state_dict(), PATH)</code></pre></div>
<p><strong>Load:</strong></p>
<div class="hljs"><pre><code class="hljs plain">device = torch.device(&apos;cpu&apos;)
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH, map_location=device))</code></pre></div>
<h3 id="Save-on-GPU-Load-on-GPU"><a href="#Save-on-GPU-Load-on-GPU" class="headerlink" title="Save on GPU, Load on GPU"></a>Save on GPU, Load on GPU</h3><p><strong>Save:</strong></p>
<div class="hljs"><pre><code class="hljs plain">torch.save(model.state_dict(), PATH)</code></pre></div>
<p><strong>Load:</strong></p>
<div class="hljs"><pre><code class="hljs plain">device = torch.device(&quot;cuda&quot;)
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH))
model.to(device)
# Make sure to call input = input.to(device) on any input tensors that you feed to the model</code></pre></div>
<p>当在GPU上训练并把模型保存在GPU，只需要使用<code>model.to(torch.device(&#39;cuda&#39;))</code>，将初始化的 model 转换为 CUDA 优化模型。另外，请 务必在所有模型输入上使用<code>.to(torch.device(&#39;cuda&#39;))</code>函数来为模型准备数据。请注意，调用<code>my_tensor.to(device)</code>会在GPU上返回<code>my_tensor</code>的副本。 因此，请记住手动覆盖张量：<code>my_tensor= my_tensor.to(torch.device(&#39;cuda&#39;))</code>。</p>
<h3 id="Save-on-CPU-Load-on-GPU"><a href="#Save-on-CPU-Load-on-GPU" class="headerlink" title="Save on CPU, Load on GPU"></a>Save on CPU, Load on GPU</h3><p><strong>Save:</strong></p>
<div class="hljs"><pre><code class="hljs plain">torch.save(model.state_dict(), PATH)</code></pre></div>
<p><strong>Load:</strong></p>
<div class="hljs"><pre><code class="hljs plain">device = torch.device(&quot;cuda&quot;)
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want
model.to(device)
# Make sure to call input = input.to(device) on any input tensors that you feed to the model</code></pre></div>
<p>在CPU上训练好并保存的模型加载到GPU时，将<code>torch.load()</code>函数中的<code>map_location</code>参数设置为<code>cuda:device_id</code>。这会将模型加载到 指定的GPU设备。接下来，请务必调用<code>model.to(torch.device(&#39;cuda&#39;))</code>将模型的参数张量转换为 CUDA 张量。最后，确保在所有模型输入上使用 <code>.to(torch.device(&#39;cuda&#39;))</code>函数来为CUDA优化模型。请注意，调用<code>my_tensor.to(device)</code>会在GPU上返回<code>my_tensor</code>的新副本。它不会覆盖<code>my_tensor</code>。 因此， 请手动覆盖张量<code>my_tensor = my_tensor.to(torch.device(&#39;cuda&#39;))</code>。</p>
<h3 id="Saving-torch-nn-DataParallel-Models"><a href="#Saving-torch-nn-DataParallel-Models" class="headerlink" title="Saving torch.nn.DataParallel Models"></a>Saving <code>torch.nn.DataParallel</code> Models</h3><p><strong>Save:</strong></p>
<div class="hljs"><pre><code class="hljs plain">torch.save(model.module.state_dict(), PATH)</code></pre></div>
<p><strong>Load:</strong></p>
<div class="hljs"><pre><code class="hljs plain"># Load to whatever device you want</code></pre></div>
<p><code>torch.nn.DataParallel</code>是一个模型封装，支持并行GPU使用。要普通保存 DataParallel 模型, 请保存<code>model.module.state_dict()</code>。 这样，你就可以非常灵活地以任何方式加载模型到你想要的设备中。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="http://pytorch123.com/" target="_blank" rel="noopener">http://pytorch123.com/</a></li>
</ol>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/PyTorch/">PyTorch</a>
                    
                  </div>
                
              </div>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/01/14/%E6%9D%BE%E5%B1%B1%E6%B9%96/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">松山湖</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/01/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/">
                        <span class="hidden-mobile">C++编程基础</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script defer src="https://cdn.staticfile.org/valine/1.4.4/Valine.min.js" ></script>

  <script type="text/javascript">
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();

      new Valine({
        el: "#vcomments",
        app_id: "iDVdqah8oVl5qmT8UM7qmde9-gzGzoHsz",
        app_key: "wqRfy95wLQRm4b7BByawaNCK",
        placeholder: "说点什么吧",
        path: window.location.pathname,
        avatar: "retro",
        meta: ["nick","mail","link"],
        pageSize: "10",
        lang: "zh-CN",
        highlight: false,
        recordIP: false,
        serverURLs: "",
      });
    };
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <b>2020</b>
      <i class="iconfont icon-love"></i>
      <b>lil-q</b>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      <span id="busuanzi_value_site_pv"></span>次访问 |
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      <span id="busuanzi_value_site_uv"></span>人来过
    </span>
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "PyTorch基础&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>


















</body>
</html>
